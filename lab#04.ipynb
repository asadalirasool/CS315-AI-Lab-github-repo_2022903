{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_FmYVNAQ4vY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(titanic_data.head())\n",
        "\n",
        "# Visualize the distribution of key features\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Distribution of Pclass\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.countplot(data=titanic_data, x='Pclass')\n",
        "plt.title('Passenger Class Distribution')\n",
        "\n",
        "# Age distribution\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.histplot(titanic_data['Age'].dropna(), bins=30, kde=True)\n",
        "plt.title('Age Distribution')\n",
        "\n",
        "# Gender distribution\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.countplot(data=titanic_data, x='Sex')\n",
        "plt.title('Gender Distribution')\n",
        "\n",
        "# Fare distribution\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.histplot(titanic_data['Fare'], bins=30, kde=True)\n",
        "plt.title('Fare Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for missing values\n",
        "print(titanic_data.isnull().sum())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# k-NN model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predictions\n",
        "knn_pred = knn.predict(X_test)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# Evaluation metrics for k-NN\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred)\n",
        "knn_recall = recall_score(y_test, knn_pred)\n",
        "knn_f1 = f1_score(y_test, knn_pred)\n",
        "\n",
        "# Evaluation metrics for Decision Tree\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred)\n",
        "dt_recall = recall_score(y_test, dt_pred)\n",
        "dt_f1 = f1_score(y_test, dt_pred)\n",
        "\n",
        "# Display the results\n",
        "metrics = {\n",
        "    'Model': ['k-NN', 'Decision Tree'],\n",
        "    'Accuracy': [knn_accuracy, dt_accuracy],\n",
        "    'Precision': [knn_precision, dt_precision],\n",
        "    'Recall': [knn_recall, dt_recall],\n",
        "    'F1 Score': [knn_f1, dt_f1],\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "print(metrics_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Using only 'Pclass' and 'Fare' for visualization purposes\n",
        "X_vis = X[['Pclass', 'Fare']]\n",
        "X_vis_train, X_vis_test, y_vis_train, y_vis_test = train_test_split(X_vis, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Plot decision boundaries for k-NN\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
        "    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolor='k')\n",
        "    plt.title(f'Decision Boundary for {model.__class__.__name__}')\n",
        "    plt.xlabel('Pclass')\n",
        "    plt.ylabel('Fare')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_decision_boundary(knn, X_vis_train, y_vis_train)\n",
        "plt.title('k-NN Decision Boundary')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_decision_boundary(dt, X_vis_train, y_vis_train)\n",
        "plt.title('Decision Tree Decision Boundary')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Bar chart for performance metrics\n",
        "metrics_df.set_index('Model').plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    }
  ]
}